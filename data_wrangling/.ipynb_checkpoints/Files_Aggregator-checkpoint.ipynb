{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Aggregator\n",
    "\n",
    "This script is used for market data combination and serialisation into a pickle file, for ease and faster use of the data for training the model. Use this script **after** the data has been aggregated and cleaned through a bash script, named `CSVCombiner.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function, global variable, and source & target absolute path declaration\n",
    "\n",
    "**Change** the absolute path when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data absolute path\n",
    "source_path='../new_data/.staging/'\n",
    "source_prefix = 'HK'\n",
    "source_postfix = '_cleaned.csv'\n",
    "target_path='../new_data/Processed/'\n",
    "target_postfix = '.pkl'\n",
    "\n",
    "# column number in the data (csv file) which is used: date, high, low, close and open price, and trade volume\n",
    "cols = list(range(6))\n",
    "\n",
    "# helper function\n",
    "def parser(x):\n",
    "    try:\n",
    "        try:\n",
    "            return pd.datetime.strptime(x, '%Y-%m-%d %H:%M')\n",
    "        except: \n",
    "            return pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return pd.datetime.strptime(x, '%Y/%m/%d %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks going to be used declaration. Both company code (HSBC, HSE, TCEHY for Tencent) and its ticker are needed as the data is named after the ticker. Make sure that data has been aggregated using the bash script (present in the `[project_root_directory]/new_data/.staging/` directory ). \n",
    "\n",
    "Each item in the *tickers* should correspond to each item in the *companyCode* in the same order (i.e. i<sup>th</sup> *tickers* item is the ticker for i<sup>th</sup> *companyCode* item)\n",
    "\n",
    "**Change** the desired stocks (ticker and company code) as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i.e. 'TCEHY': d_0700, 'CNOOC': d_0883, 'HSBC': d_0005, 'HSE': d_0011, 'AIA': d_1299, 'BOC': d_3988\n",
    "tickers = ['0011', '3988', '1299']\n",
    "companyCode=['HSE', 'BOC', 'AIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting stock HK 0011 ...\n",
      "Getting stock HK 3988 ...\n",
      "Getting stock HK 1299 ...\n",
      "Data retrieval done! \n",
      "\n",
      "                     adj_open  adj_close  adj_high  adj_low  adj_volume\n",
      "Date                                                                   \n",
      "2015-01-02 09:21:00     129.1      129.1     129.1    129.1        6000\n",
      "2015-01-02 09:31:00     129.1      129.1     129.2    129.0        3610\n",
      "2015-01-02 09:32:00     129.2      129.2     129.2    129.2         100\n",
      "                     adj_open  adj_close  adj_high  adj_low  adj_volume\n",
      "Date                                                                   \n",
      "2017-12-29 15:58:00     194.1      194.2     194.1    194.2          41\n",
      "2017-12-29 15:59:00     194.1      194.2     194.1    194.2          50\n",
      "2017-12-29 16:00:00     194.2      194.0     194.0    194.2         723\n"
     ]
    }
   ],
   "source": [
    "# retrieving and combining the data into a single list, and renamed the column header accordingly\n",
    "#     index_col specifies that the date and time to be the index\n",
    "#     parse_dates and date_parser normalise the format of the date and time to be consistent\n",
    "market_data = []\n",
    "for ticker in tickers:\n",
    "    print(\"Getting stock HK\", ticker, \"...\")\n",
    "    stock_data = pd.read_csv(source_path+source_prefix+ticker+source_postfix, usecols=cols, index_col=[0], \n",
    "                             parse_dates=[0], date_parser=parser)\n",
    "    stock_data = stock_data.rename(index=str, columns={\"Open\": \"adj_open\", \"Close\": \"adj_close\",\"High\": \"adj_high\",\n",
    "                                                       \"Low\": \"adj_low\", \"Volume\": \"adj_volume\"})\n",
    "    cols_ = stock_data.columns.tolist()\n",
    "    market_data.append(stock_data[[cols_[0], cols_[3], cols_[2], cols_[1], cols_[4]]])\n",
    "print('Data retrieval done! \\n')\n",
    "\n",
    "# sanity check\n",
    "df=market_data[0]\n",
    "print(df.head(3))\n",
    "print(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.panel.Panel'>\n",
      "Dimensions: 3 (items) x 234429 (major_axis) x 5 (minor_axis)\n",
      "Items axis: HSE to AIA\n",
      "Major_axis axis: 2015-01-02 09:21:00 to 2017-12-29 16:00:00\n",
      "Minor_axis axis: adj_open to adj_volume\n",
      "Index(['HSE', 'BOC', 'AIA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# change the data placeholder into a pandas Panel as it provides easy access for 3D data.\n",
    "#    First dimension / item: company stock (i.e. HSE, AIA)\n",
    "#    Second dimension / major_axis: data point at a single discrete date and time (i.e. prices at a particular time)\n",
    "#    Third dimension / minor_axis: data type (i.e. closing price, volume traded, high price)\n",
    "data = {code: data_ for code, data_ in zip(companyCode, market_data)}\n",
    "data = pd.core.panel.Panel(data)\n",
    "\n",
    "# sanity check\n",
    "print(data)\n",
    "print(data.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the serialised file name. The default is `market_data_[all_company_codes`.\n",
    "\n",
    "**Change** the file name as necessary, make sure to use `.pkl` extension at the end of the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file directory: ../new_data/Processed/market_data_HSE_BOC_AIA.pkl\n"
     ]
    }
   ],
   "source": [
    "data_name = \"market_data\"\n",
    "for stock in companyCode:\n",
    "    data_name += '_' + stock\n",
    "\n",
    "# specify the file type\n",
    "data_name += target_postfix\n",
    "\n",
    "print(\"file directory:\", target_path+data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.panel.Panel'>\n",
      "Dimensions: 3 (items) x 234429 (major_axis) x 5 (minor_axis)\n",
      "Items axis: HSE to AIA\n",
      "Major_axis axis: 2015-01-02 09:21:00 to 2017-12-29 16:00:00\n",
      "Minor_axis axis: adj_open to adj_volume\n",
      "Index(['HSE', 'BOC', 'AIA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# save the data in the form of pandas' Panel as pickle file\n",
    "data.to_pickle(target_path+data_name)\n",
    "\n",
    "# sanity check\n",
    "with open(target_path+data_name, \"rb\") as input:\n",
    "    mdata = pickle.load(input)\n",
    "print(mdata)\n",
    "print(mdata.items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
